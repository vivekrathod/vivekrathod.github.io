---
title: Uploading large files using WCF
date: 2009-07-20 10:32:00 Z
tags:
- WCF
layout: post
author: Vivek Rathod
modified_time: '2014-02-16T22:16:18.617-05:00'
blogger_id: tag:blogger.com,1999:blog-3203466822740858620.post-7939940984174809102
blogger_orig_url: https://blog.vivekrathod.com/2009/07/uploading-large-files-using-wcf.html
---

<div dir="ltr" style="text-align: left;" trbidi="on"><div id="_mcePaste"><div>In WCF, uploading large files (or transferring large data, in general) can be achieved in two ways - one way involves configuring the 'binding' to use 'streamed' mode while other involves using the 'buffered' mode. In the 'buffered' mode, all the data to be sent is buffered in memory at the client, and then put on the wire. On the service side, again, all the sent data is buffered before delivering it to the service. In the 'streamed' mode, the data is delivered as it is received by the underlying transport. Microsoft recommends using the 'buffered' mode whenever possible. I'll be talking about 'buffered' mode in this post.</div><div id="_mcePaste"><div></div><div id="_mcePaste"></div><div>&nbsp;Lets take a simple service implementation as shown below</div><div></div><div id="_mcePaste"></div><blockquote><pre class="csharpcode"><span class="rem">//service contract</span><br />[OperationContract]<br /><span class="kwrd">void</span> UploadData(<span class="kwrd">byte</span>[] data, <span class="kwrd">int</span> length);<br /><br /><span class="rem">//service implementation</span><br /><span class="kwrd">public</span> <span class="kwrd">void</span> UploadData(<span class="kwrd">byte</span>[] data, <span class="kwrd">int</span> length)<br />{<br />...<br />.. <br />       <span class="kwrd">using</span> (FileStream fs = <span class="kwrd">new</span> FileStream(_filePath, FileMode.Create, FileAccess.Write)<br />       {<br />           fs.write(data, 0, length);<br />       }<br />...<br />..<br />}</pre><div></div></blockquote>Here, ‘data’ is a byte array that contains file data and 'length' is the amount of data to be written. A client will then read the file as a byte array and invoke the service. On the receiving side the service simply writes the received byte array to a local file. But there is a big catch here. If the file size is multiple GBs, for example, then WCF will attempt to buffer it in memory before delivering it to the service, thus consuming multiple GBs of RAM for one file transfer. Obviously, this is not the best solution.<br /><br /><div id="_mcePaste">One simple solution to avoid this issue is to split the file into multiple smaller sized chunks and send them in each service call. This way only the memory required to hold the chunk would be consumed in each call. The service implementation would then take care of putting them together to form the original file. Here’s some code for doing this on the client side</div><br /><blockquote><pre class="csharpcode"><span class="rem">// client code</span><br /><span class="kwrd">void</span> SendFile(<span class="kwrd">string</span> fileToSend, UploadServiceClient client)<br />{<br />  <span class="rem">// uniquely identifies the file to the service</span><br />  <span class="kwrd">string</span> guid = Guid.NewGuid().ToString();<br /><br />  <span class="rem">// amount of data to be sent in each service call</span><br />  <span class="kwrd">const</span> <span class="kwrd">int</span> chunkSize = 20 * 1024 * 1024; <span class="rem">//20MB chunk</span><br />  <span class="kwrd">byte</span>[] fileData = <span class="kwrd">new</span> <span class="kwrd">byte</span>[chunkSize];<br /><br />  <span class="kwrd">using</span> (FileStream fs = File.OpenRead(fileToSend))<br />  {<br />     <span class="kwrd">int</span> bytesRead = 0;<br />     <span class="rem">// keep reading and sending the chunks over</span><br />     <span class="kwrd">while</span> ((bytesRead = fs.Read(fileData, 0, fileData.Length)) != 0)<br />     {<br />         client.UploadData(guid, fileData, bytesRead);<br />     }<br />  }<br />}</pre></blockquote><div>The service implementation code would need to be modified accordingly..</div><br /><blockquote><pre class="csharpcode"><span class="rem">// service code</span><br />Dictionary&lt;<span class="kwrd">string</span>, FileStream&gt; _files = <span class="kwrd">new</span> Dictionary&lt;<span class="kwrd">string</span>, FileStream&gt;();<br /><span class="kwrd">void</span> UploadData(<span class="kwrd">string</span> guid, <span class="kwrd">byte</span>[] data, <span class="kwrd">int</span> noOfBytesToWrite)<br />{<br />   FileStream fs;<br />   <span class="kwrd">if</span> (_files.ContainsKey(guid))<br />   {<br />       fs = _files[guid];<br />   }<br />   <span class="kwrd">else</span><br />   {<br />      fs = <span class="kwrd">new</span> FileStream(guid, FileMode.OpenOrCreate, FileAccess.Write);<br />   }<br />   fs.Write(fileData, 0, noOfBytesToWrite);<br />}</pre></blockquote><div>The client invokes the service for each chunk it wants to send over until the file is completely read. A unique 'guid' is created for each file the client wishes to send. On the service side, this 'guid' helps identify the correct FileStream to use when writing the received data to a local file. Notice that we are using chunks of size of 20MB, but this is not going to work out-of-the-box.</div><br /><div>&nbsp;WCF standard bindings have a default limit (MaxReceivedMessageSize) of 64KB on the size of the 'message' that can be received. Note that the limit is on the 'message' size so the overhead caused by SOAP header and XML attributes/elements required to form the SOAP message should also be taken into account. Also, by default, the HTTP based standard bindings (BasicHttpBinding and WsHttpBinding) base64 encode binary data (the 'data' byte array in our case), which would again increase the size of the 'message' by approximately 4/3 times. So, to send 20MB of data we need to set MaxReceivedMessageSize to at least a little over 26MB. The Net* bindings do not have this issue, but then they are WCF specific and not recommended by Microsoft where maximum interoperability is needed.</div><br /><div>&nbsp;Another important factor we need to take into consideration is the no of elements in the array being received. This is controlled by the MaxArrayLength value of the ReaderQuotas (type XmlDictionaryReaderQuotas) property of the 'binding'. This number determines the max allowed length of the array that could be received. The default is 16384, which again in our case should be changed to 20*1024.&nbsp; All these properties can also be set in app.config</div><blockquote><pre class="csharpcode">..<br /><span class="kwrd">&lt;</span><span class="html">bindings</span><span class="kwrd">&gt;</span><br />      <span class="kwrd">&lt;</span><span class="html">basicHttpBinding</span><span class="kwrd">&gt;</span><br />             <span class="kwrd">&lt;</span><span class="html">binding</span> <span class="attr">name</span><span class="kwrd">="ChunkedUpload"</span> <span class="attr">maxReceivedMessageSize</span><span class="kwrd">="30000"</span><span class="kwrd">&gt;</span><br />                       <span class="kwrd">&lt;</span><span class="html">readerQuotas</span> <span class="attr">maxArrayLength</span><span class="kwrd">="30000"</span> <span class="kwrd">/&gt;</span><br />             <span class="kwrd">&lt;/</span><span class="html">binding</span><span class="kwrd">&gt;</span><br />      <span class="kwrd">&lt;/</span><span class="html">basicHttpBinding</span><span class="kwrd">&gt;</span><br />...</pre></blockquote>Another factor to take into account is the possibility of timeouts when sending data over slower networks. The default 'send' and 'receive' timeouts (SendTimeout and ReceiveTimeout) for standard WCF bindings are about 1 min. These timeouts apply to each service call, so, on an internal network (100/10000Mbps LAN) 20MBs should be easily sent and received within a min.</div></div></div>